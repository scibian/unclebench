<?xml version="1.0" encoding="utf-8"?>
<jube>

    <include-path>
	<path> $UBENCH_PLATFORM_DIR </path>
    </include-path>
    <include from="platforms.xml" path="include-path"/>

		<multisource>
		<source protocol="https">
			<url>https://software.intel.com/sites/default/files/managed/a3/53/</url>
			<file>/IMB_2017.tgz</file>
		</source>
		</multisource>


    <benchmark name="IMB" outpath="benchmark_runs">
	<comment>A MPI benchmark</comment>

	<fileset name="source">
	    <link> $UBENCH_RESOURCE_DIR/imb/IMB_2017.tgz</link>
	    <prepare>tar  -xzf IMB_2017.tgz --strip-components=1</prepare>
	</fileset>

	<substituteset name="sub_mpicomp">
	    <iofile in="imb/src/make_ict" out="imb/src/make_ict"/>
	    <sub source="#MPICOMP#" dest="$mpi_cc"/>
	</substituteset>
	<parameterset name="compiler_set" init_with="platform.xml">
	    <parameter name="comp_v">1</parameter>
	</parameterset>


	<parameterset name="mpi_set" init_with="platform.xml">
	    <parameter name="mpi_v">0</parameter>
	</parameterset>


	<!-- =====================  Compile  ===================== -->
	<step name="compile" export="true">

	  <!-- Choose compiler and MPI versions -->
	  <use from="platform.xml"> mpi_set </use>
	    <!-- <use> mpi_set </use> -->
	    <use> compiler_set </use>
	    <!-- substitute compiler in makefile -->
	    <use>source</use>
	    <use>sub_mpicomp</use>

	    <!-- Load environment -->
	    <do> module purge </do>
	    <do> module load $module_compile $module_mpi </do>

	    <do> mkdir exe </do>
	    <do work_dir="imb/src"> make -f make_ict IMB-MPI1 </do>
	    <do work_dir="imb/src"> mv IMB-MPI1 ../../exe/. </do>

	</step>

	<!-- =====================  Execute  ===================== -->

	<fileset name="binaries">
	    <link rel_path_ref="internal" directory="compile/exe">
		IMB-MPI1
	    </link>
	</fileset>

	<parameterset name="system_parameters" init_with="platform.xml">
	    <parameter name="nodes" type="int">1,2</parameter>
	    <parameter name="taskspernode" mode="python" type="int">$NUMA_regions * $cores_per_NUMA_region</parameter>
	    <parameter name="threadspertask" type="int">1</parameter>
	    <parameter name="executable">./IMB-MPI1</parameter>
	    <parameter name="args_exec" separator="??">pingpong sendrecv allreduce alltoallv -off_cache ${MB_LLC_size},${LLC_cache_line_size} -map ${taskspernode}x${nodes} -msglog 1:18</parameter>
	    <parameter name="modules">$module_compile $module_mpi</parameter>
	    <parameter name="timelimit">01:00:00</parameter>
	</parameterset>


	<step name="execute" depend="compile">
	    <use>binaries</use>
	    <use from="platform.xml">execute_set</use>

	    <use from="platform.xml">cluster_specs</use>
	    <use>system_parameters</use>

	    <use from="platform.xml">jobfiles</use>
	    <use from="platform.xml">execute_sub</use>
	    <do done_file="$done_file">$submit $submit_script</do>
	</step>

	<!-- =====================  Analyze  ===================== -->

	<patternset name="pattern">
	    <pattern name="ping_pong2" reduce="last">(\s+$jube_pat_int\s+$jube_pat_int\s+$jube_pat_nfp\s+$jube_pat_fp){2}</pattern>
	    <pattern name="ping_pong4" reduce="last">(\s+$jube_pat_int\s+$jube_pat_int\s+$jube_pat_nfp\s+$jube_pat_fp){3}</pattern>
	    <pattern name="ping_pong8" reduce="last">(\s+$jube_pat_int\s+$jube_pat_int\s+$jube_pat_nfp\s+$jube_pat_fp){4}</pattern>
	    <pattern name="ping_pong16" reduce="last">(\s+$jube_pat_int\s+$jube_pat_int\s+$jube_pat_nfp\s+$jube_pat_fp){5}</pattern>
	    <pattern name="ping_pong32" reduce="last">(\s+$jube_pat_int\s+$jube_pat_int\s+$jube_pat_nfp\s+$jube_pat_fp){6}</pattern>
        </patternset>

	<analyzer name="analyse">
	    <use>pattern</use>
	    <analyse step="execute"><file>job.out</file></analyse>
        </analyzer>

	<result>
	    <use>analyse</use>
	    <table name="result" style="pretty">
		<column>ping_pong2</column>
		<column>ping_pong4</column>
		<column>ping_pong8</column>
		<column>ping_pong16</column>
		<column>ping_pong32</column>
		<column>module_mpi</column>
	    </table>
        </result>


    </benchmark>
</jube>
